{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        self.train_errors = [] \n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs  = np.array(inputs_list , ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        \n",
    "        output_errors = targets - output_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        self.who += self.lr * np.dot((output_errors * output_outputs * (1 - output_outputs)), np.transpose(hidden_outputs))\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        self.train_errors.append(np.sum(output_errors**2)) \n",
    "    \n",
    "        pass\n",
    "    \n",
    "    def query(self, inputs_lists):\n",
    "        inputs = np.array(inputs_lists, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        \n",
    "        return output_outputs\n",
    "    \n",
    "    def return_wih(self):\n",
    "        return self.wih\n",
    "    def return_who(self):\n",
    "        return self.who\n",
    "    def return_err(self):\n",
    "        return self.train_errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found training df\n",
      "found testing df\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f = open('MNIST_Train_extended.pckl', 'rb')\n",
    "    traindf = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"found training df\")\n",
    "    creation_of_training_df_required = False\n",
    "except:\n",
    "    traindf = pd.DataFrame()\n",
    "    print(\"training df not found creation required\")\n",
    "    creation_of_training_df_required = True\n",
    "\n",
    "try:\n",
    "    f = open('MNIST_Test.pckl', 'rb')\n",
    "    testdf = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"found testing df\")\n",
    "    creation_of_testing_df_required = False\n",
    "except:\n",
    "    testdf = pd.DataFrame()\n",
    "    print(\"testing df not found creation required\")\n",
    "    creation_of_testing_df_required = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden       = (5, 10, 20, 50, 100, 200, 250, 300)\n",
    "LearningRate = (0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.3)\n",
    "epochs       = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer count 5\n",
      "learning rate 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-81699eb7a67b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_blr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_rtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-904a1d59d9dc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs_list, targets_list)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mhidden_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwho\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_errors\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput_outputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwih\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_errors\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_outputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhidden_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_nodes   = 28*28\n",
    "output_nodes  = 10\n",
    "\n",
    "NNperformance = pd.DataFrame()\n",
    "\n",
    "for h in hidden:\n",
    "    hidden_nodes = h\n",
    "    print('hidden layer count '+str(h))\n",
    "    for L in LearningRate:\n",
    "        learning_rate = L\n",
    "        print('learning rate '+str(L))\n",
    "        n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "        for e in range(epochs):\n",
    "            start_time = time.time()\n",
    "            # print('epoch '+str(e))\n",
    "            for index, row in traindf.iterrows():\n",
    "                input_raw  = row['image']\n",
    "                input_blr  = row['blurred']\n",
    "                input_rtp  = row['rotplus10']\n",
    "                input_rtm  = row['rotminu10']\n",
    "                targets = np.zeros(output_nodes) + 0.01\n",
    "                targets[int(row['Label'])] = 0.99\n",
    "                n.train(input_raw, targets)\n",
    "                n.train(input_blr, targets)\n",
    "                n.train(input_rtp, targets)\n",
    "                n.train(input_rtm, targets)\n",
    "                pass\n",
    "            scorecard=[]\n",
    "            for index, row in testdf.iterrows():\n",
    "                input_raw     = row['image']\n",
    "                correct_label = row['Label']\n",
    "                output  = n.query(input_raw)\n",
    "                label   = np.argmax(output)\n",
    "                if (label == correct_label):\n",
    "                    scorecard.append(1)\n",
    "                else:\n",
    "                    scorecard.append(0)\n",
    "                    pass\n",
    "                pass\n",
    "\n",
    "            performance = np.asarray(scorecard).sum() / np.asarray(scorecard).size\n",
    "            newdf = pd.DataFrame({'hidden_node_count' : h,\n",
    "                                      'learning_rate' : L,\n",
    "                                               'epoch': e,\n",
    "                                         'performance': [\"%.5f\" % performance]})\n",
    "            NNperformance = NNperformance.append(newdf,  sort=True, ignore_index=True)[newdf.columns.tolist()]\n",
    "            #print(time.time() - start_time)\n",
    "            pass\n",
    "        NNperformance.to_csv('exp_'+datetime.now().strftime('%Y%m%d_%H%M%S')+'.csv', sep=',', encoding='utf-8')\n",
    "        pass\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNperformance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
