{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        self.train_errors = [] \n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs  = np.array(inputs_list , ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        \n",
    "        output_errors = targets - output_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        self.who += self.lr * np.dot((output_errors * output_outputs * (1 - output_outputs)), np.transpose(hidden_outputs))\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        self.train_errors.append(np.sum(output_errors**2)) \n",
    "    \n",
    "        pass\n",
    "    \n",
    "    def query(self, inputs_lists):\n",
    "        inputs = np.array(inputs_lists, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        \n",
    "        return output_outputs\n",
    "    \n",
    "    def return_wih(self):\n",
    "        return self.wih\n",
    "    def return_who(self):\n",
    "        return self.who\n",
    "    def return_err(self):\n",
    "        return self.train_errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open('MNIST_Train_extended.pckl', 'rb')\n",
    "    traindf = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"found training df\")\n",
    "    creation_of_training_df_required = False\n",
    "except:\n",
    "    traindf = pd.DataFrame()\n",
    "    print(\"training df not found creation required\")\n",
    "    creation_of_training_df_required = True\n",
    "\n",
    "try:\n",
    "    f = open('MNIST_Test.pckl', 'rb')\n",
    "    testdf = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"found testing df\")\n",
    "    creation_of_testing_df_required = False\n",
    "except:\n",
    "    testdf = pd.DataFrame()\n",
    "    print(\"testing df not found creation required\")\n",
    "    creation_of_testing_df_required = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden       = (5, 10, 20, 50, 100, 200, 250, 300)\n",
    "LearningRate = (0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.3)\n",
    "epochs       = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes   = 28*28\n",
    "output_nodes  = 10\n",
    "\n",
    "NNperformance = pd.DataFrame()\n",
    "\n",
    "for h in hidden:\n",
    "    hidden_nodes = h\n",
    "    print('hidden layer count '+str(h))\n",
    "    for L in LearningRate:\n",
    "        learning_rate = L\n",
    "        print('learning rate '+str(L))\n",
    "        n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "        for e in range(epochs):\n",
    "            start_time = time.time()\n",
    "            # print('epoch '+str(e))\n",
    "            for index, row in traindf.iterrows():\n",
    "                input_raw  = row['image']\n",
    "                input_blr  = row['blurred']\n",
    "                input_rtp  = row['rotplus10']\n",
    "                input_rtm  = row['rotminu10']\n",
    "                targets = np.zeros(output_nodes) + 0.01\n",
    "                targets[int(row['Label'])] = 0.99\n",
    "                n.train(input_raw, targets)\n",
    "                n.train(input_blr, targets)\n",
    "                n.train(input_rtp, targets)\n",
    "                n.train(input_rtm, targets)\n",
    "                pass\n",
    "            scorecard=[]\n",
    "            for index, row in testdf.iterrows():\n",
    "                input_raw     = row['image']\n",
    "                correct_label = row['Label']\n",
    "                output  = n.query(input_raw)\n",
    "                label   = np.argmax(output)\n",
    "                if (label == correct_label):\n",
    "                    scorecard.append(1)\n",
    "                else:\n",
    "                    scorecard.append(0)\n",
    "                    pass\n",
    "                pass\n",
    "\n",
    "            performance = np.asarray(scorecard).sum() / np.asarray(scorecard).size\n",
    "            newdf = pd.DataFrame({'hidden_node_count' : h,\n",
    "                                      'learning_rate' : L,\n",
    "                                               'epoch': e,\n",
    "                                         'performance': [\"%.5f\" % performance]})\n",
    "            NNperformance = NNperformance.append(newdf,  sort=True, ignore_index=True)[newdf.columns.tolist()]\n",
    "            print(time.time() - start_time)\n",
    "            pass\n",
    "        pass\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNperformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
